---
title: "A demonstration of combined scientific data processing and publication using Literate Programming in R"
author: "Andy Clifton"
date: '`r Sys.Date()`'
output:
  bookdown::pdf_document2:
    latex_engine: pdflatex
    toc: true
    number_sections: true
    fig_caption: true
    keep_tex: true
    citation_package: natbib
  md_document:
    variant: gfm
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
fontsize: 11pt
geometry: margin=1in
graphics: yes
bibliography: main.bib
linkcolor: blue
urlcolor: red
citecolor: cyan
link_citations: true
---
<!-- ## If you are reading the source code
This is R Markdown. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com> or <http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html>.

This script is designed to be used with knitr in R. -->

# Introduction

Something something reproducible research, mumble, grumble, get off my lawn, grumble.

## Linking analysis and publication workflows
Anecdotally, the separation of the publication from the analysis process has been a barrier to reproducible research, as it is impossible to ensure the link between source data and final publication.

This document demonstrates the application of Literate Programming to reproducible research. Literate programming means that the program documentation is complete and contained within the program itself [@Knuth1984]^[Yes, that's the same `Knuth' who invented LaTeX]. It is important to note that the documentation is effectively a publication, and thus it is possible to combine data analysis with the creation of a publication in the same file. The use of literate programming therefore mitigates this barrier to reproducible research.

Furthermore, this project has been structured so that the data required for this publication are in a subdirectory of the project. This means that all of the files required to reproduce the analysis results can be included in a repository.

## How Literate Programming was used to write this document
In this example, an output PDF document and results are generated from a file called _main.rmd_. _main.rmd_ is an [R markdown file](https://rmarkdown.rstudio.com/authoring_basics.html). R markdown is a flavor of markdown that can be processed by the R programming language [@R-base] to run code (i.e, do analysis) and create documentation from the same document. This is done using a package called _knitr_. Instructions for how to run _knitr_ are included in the _howto.md_ file in this repository. A far more detailed guide to writing using R markdown can be found in @R-Markdown-Guide.

The markdown document contains a mixture of documentation -- written in markdown or LaTeX - and so-called ``code chunks'', which here are written in R. The output is a PDF.

 * The .rmd document is written in Pandoc markdown, which looks like normal text.
 * The document contains code chunks that look like this:

````
`r ''````{r, echo=TRUE}
y = 40 + 2
print(y)
```
````
.. which evaluates to

```{r y1, echo=TRUE}
y = 40 + 2
print(y)
```

 * The code chunks can be configured so that their outputs are echoed to the document (or not), which in turn allows the output PDF to show only those parts of the data processing that are relevant. You can thus completely hide the data operations in your output PDF and just display the results that are relevant.
 * It is possible to use other programming languages by replacing the `{r,' in the code chunk with the name of another language (see [``Please not  R''](#pleaseNotR))
 * There are a lot of different possible output formats, including PDF, HTML, Notebooks, other markdown formats, and many others. Corporate formatting can usually be applied without modifying their content. The details of this are out of scope for this paper; instead, see [@R-Markdown-Guide] or  https://bookdown.org/yihui/rmarkdown/documents.html for more information.

I suggest reading this PDF together with the R markdown file (_main.rmd_) and possibly the _knitr_ instructions^[See https://yihui.name/knitr/]. This will greatly help in understanding what is done in the processing and what makes it to the publication.

<!-- ## Execute some code without displaying results. -->

```{r clean up, echo = FALSE}
rm(list = ls())
```

## Please not R {#pleaseNotR}
If you can't handle learning yet another new language, this next statement might interest you:

> "A less well-known fact about R Markdown is that many other languages are also supported, such as Python, Julia, C++, and SQL. The support comes from the knitr package, which has provided a large number of language engines.""
>
> --- @R-Markdown-Guide

The currently available language engines are:

```{r languages,}
require(knitr)
names(knitr::knit_engines$get())
```

So, you have no excuse. You can write your code in any of those `r NROW(names(knitr::knit_engines$get()))` languages, and off you go. A possible source of confusion might be that the rest of the document is R-flavoured markdown, but honestly there's not really that much R about it.

# Implementing a coupled analysis and publication workflow
An analysis and publication workflow usually follows a similar path:

1. Set up the computing environment
1. Load some external packages
1. Load our own data processing routines
1. Import data
1. Plot it
1. Do some operations
1. Plot some more
1. Write
1. Format for a journal
1. Iterate around items 1-10 for a while
1. Submit

Fortunately, all of this can be captured in a markdown document.

## Setting up the computing environment
Like most scripts, _main.rmd_ includes a few variables that the user must set to run the analysis.

 * The _project.root_ variable defines the location of the files required for this analysis.
 * The _made.by_ variable forms part of a label that will be added to the plots.

An advantage of _knitr_ is that we can simply execute the code and show the code and results inline:

```{r user-defined options, message=TRUE, results = 'hold'}
# Where can files be found?
project.root <- file.path('/Users/andyc/Documents/public/GitHub/LiterateSciencePublishingDemo')
project.root

# Who ran this script
made.by = "A. Clifton"
made.by
```

We can also show the value of those variables in the documentation using a relatively simple format, e.g. ` r _project.root_ `. This lets us then record in the documentation that

 * _project.root_ is `r project.root`
 * _made.by_  is `r made.by`.

We've already set up several important subdirectories in _project.root_:

 * /__code__ contains functions required for the analysis
 * /__data__ contains the data files to be analyzed.

Let's tell the code where these are. We can also change our the working directory (_working.dir_ ) to the root directory of the project.

```{r define file locations, message=FALSE, echo = FALSE}
# define the working directory
working.dir <- project.root
setwd(working.dir)

#identify data directory
data.dir = file.path(project.root,
                     "data")

#identify code directory
code.dir = file.path(project.root,
                     "code")
```

We'll also create a new directory for the results of the analysis.

```{r make output directory, message=FALSE, echo = FALSE}
# define the path to the directory that we will use to store all of the data
output.dir = file.path(project.root,
                       "analysis",
                       "all")

# create this directory if it doesn't already exist
dir.create(output.dir,
           showWarnings = FALSE,
           recursive = TRUE)
```

Looking at your file system, you'll see there is now a new directory called  __`r output.dir`__.

## Load packages
```{r load packages, message=FALSE, echo = FALSE}
require(bookdown)
require(ggplot2)

if(packageVersion("ggplot2") < "2.2.0") {
    stop("Need package:ggplot2 2.2 or higher for labs function")
}

require(grid)
require(reshape2)
require(stringr)
```

## Loading our own routines
Every data processing workflow requires its own scripts or functions to run. In this example, they are included in the _codes_ directory and sourced during the preparation of this document. I have included output below to show these codes being called.

```{r source codes, message=TRUE, echo = TRUE}
# source these functions
code.files = dir(code.dir, pattern = "\\.R$")
for (file in code.files){
  source(file = file.path(code.dir,file))
  print(paste0("Sourcing ", file, "."))
}
```

## Load the data
We now analyse the data from the simple data set. In this case, code has been written to load all of the files in the _data.dir_   directory (`r data.dir`). I'm also going to map the three columns in the data files to the variables $x$, $y$, and $z$.^[See https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html for more information about including maths in R markdown]

```{r load individual data files, results='asis', echo = FALSE}
  # identify the data sets that we have available
  data.files = dir(data.dir,
                   recursive = TRUE,
                   pattern = "\\.csv$")

  # load each file
  for (data.file in data.files){
    # Read this data set;
    df.new <- read.csv(file.path(data.dir,
                       data.file),
                      col.names = c("x","y","z"),
             header=TRUE)
    # capture information about this data
    df.new$source = data.file
    # check for the existance of an aggregate data set. If it's not there, create a new one
    if (!exists("df.in")){
      # theres no data
      df.in <- df.new
    } else {
      # append new data
      df.in <- rbind(df.in,
                      df.new)
    }
    }
```

## Plot input data
The next step is to plot the input data. In this case we plot all of the input data together in one plot, but there are many different possibilities. Figures can also be given a consistent look and feel through ggplot's themes.

<!-- Configure graphics -->
```{r configure graphics, message=FALSE, echo = FALSE}
# configure graphics appearance
#theme_set(theme_Literate(base_size = 8,
#                         base_family = "sans"))
```

```{r plot input data, echo= FALSE, fig.show='hold', fig.width = 6, fig.height = 3}
p <- plotSomething(df=df.in,
                   made.by)
plot(p)
```

For convenience, we'll also save a copy of the figure as a _.png_ file to the _analysis_ directory.

```{r save plot of input data, message = FALSE, echo=FALSE}
ggsave(filename = file.path(output.dir,
                                  "DataAll.png"),
             plot = last_plot(),
             width = 6,
             height = 4,
             units = "in",
             dpi = 300)
```

## Operate on the data
At this point we can do any number of operations on the data. For sake of demonstration, let's add 2 to all $x$ values.

```{r add two,}
df.all <- df.in
df.all$x <- df.in$x + 2.0
```

## Plot the results
Let's run that _plotSomething_ routine again.

```{r plot modified data, echo= FALSE, fig.show='hold', fig.width = 6, fig.height = 3}
p <- plotSomething(df=df.all,
                   made.by)
plot(p)
```

And, as we can see, the data have shifted along $x$ by a small amount.

## Connect processing with publication
So far we have demonstrate that we can import and manipulate data and plot results. Another important part of a publication is the ability to generate statistics or summary information from data and include that in our text.

To demonstrate that, I can calculate that the maximum value of $y$ in the input data sets was `r max(df.all$y)`. This can be confirmed by checking the input data files. I could also include more complex logic in these statements, for example to say if one statistic is bigger or larger than another.

We sometimes need to include formatted tables in documents. This can be done using the _kable_ function (Table \@ref(tab:dfall)).

<!--- https://bookdown.org/yihui/rmarkdown/bookdown-markdown.html#bookdown-markdown --->
```{r dfall, echo = TRUE}
knitr::kable(df.all,
             format = "pandoc",
             # format = "markdown", # this breaks cross references
             booktabs=TRUE,
             caption = "The $df.all$ data frame.")
```

## Save the processed data
We now write our processed data to file.

```{r save data, echo=TRUE}
# save the data
save(list = c("project.root",
              "made.by",
              "df.all"),
       file = file.path(output.dir,"Data.RData"),
       envir = .GlobalEnv)
```

In R it is also possible to save the whole workspace. We can do that here as well:

```{r save workspace, echo=TRUE}
# save the workspace
save.image(file=file.path(output.dir,"workspace.RData"))
```

## Saving packages
<!--- ? Is it possible to save packages locally the first time they are called and then pick them up there afterwards, instead of from a repo? --->
Packages are required to supplement base functions in R and many other languages. For example, this script requires the _reticulate_, _bookdown_, _ggplot2_, _grid_, _knitr_, _RColorBrewer_, _rgdal_, and _stringr_ packages to run. These are called from the script using the _require()_ function. This assumes that the packages are available on your system.^[For details of how to install packages, see the RStudio help.] The use of packages represents a challenge to reproducable and repeatable research as it is possible that the function and output of the packages may change over time.

## Applying Journal formating
Scientific Journals often have their own formatting requirements. These requirements can still be met using markdown. The mechanics of such a process are beyond the scope of this paper and should probably be done as the last step in the publishing process. The reader is suggested to look at the _rticles_ package and to use the detailed instructions in section 13 of the R Markdown Guide [@R-Markdown-Guide].

## Thoughts on audit trails and confidentiality
Audit trails and confidentiality have implications for data (which might be commercially sensitive) and algorithms (which represent intellectual property).

A first step would be to avoid saving the workspace during the processing. Similarly, care should be taken to not commit any temporary files to a repository.

This document assumed that the data were available in text files that are stored in the same repository. However, it's equally possible that the raw data would have been called from a remote database at run time (or cached) and should be kept confidential. This can be done by not saving them to file. It would be desirable instead to store data IDs that would allow traceability. This could be combined with saving the results of the data processing, rather than the raw data.

Algorithms could be called directly from third party services or accessed via APIs. This shifts the onus to those third parties to provide the tracking required for auditting, but does preserve intellectual property.

All of these considerations can be dealt with in the data processing routines that are included in the source code of this document. There are doubtless many other issues and anyone concerned about this is encouraged to consult an expert.

## Packaging for storage
A simple solution to repeatability and reproducability may be to have a generic ``data processing'' image of a computer system, e.g. as a Docker image, that is started for each new project and used _only_ for that project. This clean system is then used for one data processing task which is managed through a file such as the one you are reading. When the project is complete, the image is simply stored for as long as required. This would also avoid problems associated with changes introduced by package and system updates. A drawback to this approach would be the need to migrate the data every 5 years or so to a new system, which would be required to avoid data being stranded on old software.

# Conclusions
Literate programming allows the creation of a single document that captures all of the process of preparing and analysing data, and creating a publication to describe that data. This is a fundamental requirement of reproducible research.

# Referencing this document {-}
This document has been assigned the Digital Object Identifier [10.5281/zenodo.3497450](http://dx.doi.org/10.5281/zenodo.3497450). Citations in a range of formats can be obtained through Zenodo.

[![DOI](DOIBadge3497450.pdf)](https://doi.org/10.5281/zenodo.3497450)

The source code for this document is available through [github.com/AndyClifton/LiterateDemo](https://github.com/AndyClifton/LiterateSciencePublishingDemo).

# Acknowledgements {-}

Many thanks to Nikola Vasiljevic at DTU for prompting me to get this done.

# Bibliography {-}
